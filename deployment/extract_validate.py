"""
build-and-check.py
  1.  export PPO policy weights to ppo_weights.h
  2.  copy (not overwrite) your existing ppo_controller.c into the build folder
  3.  compile a shared library (libppo_controller.{so|dylib})
  4.  run NUM_TESTS random observations through both the PyTorch policy
      and the compiled C implementation, checking that outputs match.

Exit code is 0 if validation succeeds, 1 otherwise.

Usage example:
    python deployment/extract_validate.py \
        --model /Users/merlijnbroekers/Desktop/Drone_Interception/final_models/Acc_indi_Moth_dt0p01_T1200_CapRadius0p15_Bound10_rel_pos+vel_body_His0_ActHis0_effective_gain_DR0_0820_1054/ppo_checkpoint_step_15000000.zip \
        --csrc  deployment/ppo_controller.c
"""

import argparse, platform, shutil, subprocess, sys
from pathlib import Path

import numpy as np
import torch
from stable_baselines3 import PPO

# configuration
HEADER_NAME = "ppo_weights.h"
LIB_BASE = "libppo_controller"
TOLERANCE = 1e-5
NUM_TESTS = 500
OBS_RANGE = (-100.0, 100.0)
INPUT_DIM = 18  # change to match current configuartion
OUTPUT_DIM = 3  # change to match current configuartion
# ----------------------------------------------------------------------------


def export_header(state_dict, out_path: Path) -> None:
    """Write each tensor from the policy state_dict into a single header."""

    def to_c(name: str, arr: np.ndarray, per_line: int = 8) -> str:
        flat = arr.ravel()
        body = ",\n".join(
            "    " + ", ".join(f"{x:.8f}" for x in flat[i : i + per_line])
            for i in range(0, len(flat), per_line)
        )
        return f"float {name}[{len(flat)}] = {{\n{body}\n}};\n\n"

    with out_path.open("w") as f:
        f.write("// auto-generated by extract_validate.py\n\n")
        for k, tensor in state_dict.items():
            cname = k.replace(".", "_").replace(":", "_")
            f.write(to_c(cname, tensor.cpu().numpy()))


def compile_shared(c_file: Path, out_dir: Path) -> Path:
    """Compile the copied C file into a shared library and return its path."""
    sysname = platform.system()
    lib_path = out_dir / (LIB_BASE + (".dylib" if sysname == "Darwin" else ".so"))

    cmd = (
        ["clang", "-shared", "-O3", "-fPIC", "-o", lib_path, c_file, "-lm"]
        if sysname == "Darwin"
        else ["gcc", "-shared", "-O3", "-fPIC", "-o", lib_path, c_file, "-lm"]
    )

    print("Step 4/5  Compiling C library:")
    print("          " + " ".join(str(tok) for tok in cmd))
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print("Compilation failed. Compiler output:")
        print(result.stdout)
        print(result.stderr)
        sys.exit(1)
    return lib_path


def sb3_forward(model, obs_np: np.ndarray) -> np.ndarray:
    """
    Run model.predict() with deterministic=True so we get the exact
    mean action (no exploration noise).  Returns a 1-D NumPy array.
    """
    action, _ = model.predict(obs_np, deterministic=True)
    return action.astype(np.float32)


def validate(model, lib_path: Path) -> bool:
    """Run NUM_TESTS random observations through both implementations."""
    import ctypes

    lib = ctypes.CDLL(str(lib_path))
    lib.get_action.argtypes = [
        ctypes.POINTER(ctypes.c_float),
        ctypes.POINTER(ctypes.c_float),
    ]
    lib.get_action.restype = None

    def c_forward(obs_np: np.ndarray) -> np.ndarray:
        out = np.zeros(OUTPUT_DIM, dtype=np.float32)
        lib.get_action(
            obs_np.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),
            out.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),
        )
        return out

    lo, hi = OBS_RANGE
    for i in range(NUM_TESTS):
        obs = np.random.uniform(lo, hi, size=(INPUT_DIM,)).astype(np.float32)
        act_py = sb3_forward(model, obs)
        act_c = c_forward(obs)
        if not np.allclose(act_py, act_c, atol=TOLERANCE):
            print(f"Validation failed on test {i + 1}/{NUM_TESTS}")
            print("Observation :", np.round(obs, OUTPUT_DIM))
            print("PyTorch out  :", np.round(act_py, 6))
            print("C out        :", np.round(act_c, 6))
            print(f"Absolute tolerance was {TOLERANCE}")
            return False

    print(f"Validation successful: {NUM_TESTS} / {NUM_TESTS} tests within Â±{TOLERANCE}")
    return True


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", required=True, help="Path to PPO .zip file")
    parser.add_argument(
        "--csrc",
        default="ppo_controller.c",
        help="Path to existing ppo_controller.c (not overwritten)",
    )
    parser.add_argument(
        "--workdir",
        default="deployment_build",
        help="Directory for generated files and build artefacts",
    )
    args = parser.parse_args()

    workdir = Path(args.workdir).resolve()
    workdir.mkdir(exist_ok=True)

    # 1. Load model
    print("Step 1/5  Loading model from:", args.model)
    model = PPO.load(args.model, device="cpu")
    policy = model.policy

    # 2. Export header
    header_path = workdir / HEADER_NAME
    print("Step 2/5  Exporting weights to:", header_path)
    export_header(policy.state_dict(), header_path)

    # 3. Copy C controller source
    src_in = Path(args.csrc).resolve()
    if not src_in.is_file():
        sys.exit(f"Error: cannot find controller source: {src_in}")
    src_out = workdir / src_in.name
    shutil.copy(src_in, src_out)
    print("Step 3/5  Copied C source to:", src_out)

    # 4. Compile shared library
    lib_path = compile_shared(src_out, workdir)
    print("Step 4/5  Compiled library:", lib_path)

    # 5. Validate
    print(
        f"Step 5/5  Running validation "
        f"({NUM_TESTS} random tests, tolerance {TOLERANCE}, range {OBS_RANGE})"
    )
    success = validate(model, lib_path)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
